{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in MacOS Catalina\n",
    "!pip install pyarrow==0.13.0 apache-beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache Beam Version: 2.16.0\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "\n",
    "print(\"Apache Beam Version: {}\".format(beam.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Example: WordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello: 1\n",
      "world: 1\n",
      "apache: 1\n",
      "beam: 2\n",
      "!: 2\n",
      "Nice: 1\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "    lines = p | 'Create' >> beam.Create(['hello world', 'apache beam', '! Nice beam !'])\n",
    "    counts = (\n",
    "        lines\n",
    "        | 'Split' >> beam.FlatMap(lambda x: x.split(' '))\n",
    "        | 'PairWithOne' >> beam.Map(lambda x: (x, 1))\n",
    "        | 'GroupAndSum' >> beam.CombinePerKey(sum)\n",
    "    )\n",
    "    counts | 'Print' >> beam.ParDo(lambda w: print(\"{}: {}\".format(w[0], w[1])))  # w is a tuple ('word': count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Apache Beam, three components are the keys to complete the whole job, these are `Pipeline`, `PCollection` and `Transform`.\n",
    "* Pipeline is used to construct the flow of processing data. It is also a DAG (Directed acyclic graph). The idea in MapReduce is `Job`.\n",
    "* PCollection is a type of data structure. We can edit or manipulate them. The similar idea in Spark is `RDD`.\n",
    "* Transform is progress transforming from one PCollection to another.\n",
    "\n",
    "They are shown below.\n",
    "```python\n",
    "[Output PCollection] = [Input PCollection] | [Label] >> [Transform]\n",
    "```\n",
    "\n",
    "`|` is a symbol to indicate adding a new transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Connectors: file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "    lines = p | 'ReadFromFile' >> beam.io.ReadFromText(\"/Users/jiankaiwang/Desktop/apache_beam/Dengue_Daily.csv\")\n",
    "    lines | \"WriteToFile\" >> beam.io.WriteToText(\"/Users/jiankaiwang/Desktop/apache_beam/\", file_name_suffix='.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callable, DoFn, ParDo\n",
    "\n",
    "`ParDo` requires a callable function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitFn(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        \"\"\"Necessary implementations.\"\"\"\n",
    "        \n",
    "        # only return a element whose index is 6\n",
    "        # notice the return value's type is a list [value]\n",
    "        return [element.split(\",\")[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "    lines = p | 'ReadFromFile' >> beam.io.ReadFromText(\"/Users/jiankaiwang/Desktop/apache_beam/Dengue_Daily_small.csv\")\n",
    "    extract = (\n",
    "        lines \n",
    "        | \"SplitCols\" >> beam.ParDo(SplitFn())\n",
    "        | \"PairWithValue\" >> beam.Map(lambda x: (x, 1))\n",
    "        | \"GroupAndSum\" >> beam.CombinePerKey(sum)\n",
    "    )\n",
    "    extract | \"WriteToFile\" >> beam.io.WriteToText(\"/Users/jiankaiwang/Desktop/apache_beam/\", file_name_suffix='.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitFnAndMap(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        \"\"\"Necessary implementations.\"\"\"\n",
    "        \n",
    "        # only return a element whose index is 6\n",
    "        # notice the return value's type is a tuple (key, value)\n",
    "        yield (element.split(\",\")[6], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "    lines = p | 'ReadFromFile' >> beam.io.ReadFromText(\"/Users/jiankaiwang/Desktop/apache_beam/Dengue_Daily_small.csv\")\n",
    "    extract = (\n",
    "        lines \n",
    "        | \"SplitColsAndMap\" >> beam.ParDo(SplitFnAndMap())\n",
    "        | \"GroupAndSum\" >> beam.CombinePerKey(sum)\n",
    "    )\n",
    "    extract | \"WriteToFile\" >> beam.io.WriteToText(\"/Users/jiankaiwang/Desktop/apache_beam/\", file_name_suffix='.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "http://shzhangji.com/cnblogs/2017/09/13/apache-beam-quick-start-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
